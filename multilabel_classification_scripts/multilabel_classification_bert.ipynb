{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, you need to pull:\n",
    "\n",
    "https://github.com/google-research/bert\n",
    "\n",
    "And add bert_preprocessing.py and multilabel_bert.py script from to the pulled directory (put it in the same directory with modeling.py, optimization.py, tokenization.py):\n",
    "\n",
    "https://github.com/Andoree/tweets_classification/tree/master/multilabel_classification_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import modeling\n",
    "import optimization\n",
    "import tokenization\n",
    "from bert_preprocessing import create_examples, file_based_convert_examples_to_features, \\\n",
    "    convert_examples_to_features\n",
    "from multilabel_bert import file_based_input_fn_builder, create_model, model_fn_builder, \\\n",
    "input_fn_builder, create_output, predict, get_estimator, train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: export: : bad variable name\r\n"
     ]
    }
   ],
   "source": [
    "# Setting CUDA device\n",
    "! export CUDA_VISIBLE_DEVICES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dir  = r\"otzovik_csvs/fold_0/\"\n",
    "bert_vocab_path = r\"/home/tlenusik/DATA/pretrained_models/multilingual_russian_reviews_finetuned/vocab.txt\"\n",
    "# Change checkpoint if you want to use multilanguage Bert model that is finetuned on another dataset.\n",
    "bert_init_chkpnt_path = r\"/home/tlenusik/DATA/pretrained_models/multilingual_russian_reviews_finetuned/bert_model.ckpt\"\n",
    "bert_config_path =  r\"/home/tlenusik/DATA/pretrained_models/multilingual_russian_reviews_finetuned/bert_config.json\"\n",
    "batch_size = 32\n",
    "num_train_epochs = 5\n",
    "warmup_proportion = 0.1\n",
    "max_seq_length = 128\n",
    "learning_rate = 2e-5\n",
    "save_summary_steps = 500\n",
    "output_dir = r\"results/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "predicted_proba_filename = \"predicted_labels.csv\"\n",
    "\n",
    "# Number of classes\n",
    "NUM_LABELS = 5\n",
    "# The column with this name must exist in test data\n",
    "text_column_name = 'sentences'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation\n",
    "Validation loss and accuracy for all classes is saved in \"output_dir/eval_results.txt\" (path parameters are initialized at \"Parameters\" section). \n",
    "\n",
    "The first column of csv file must contain document's text. The next NUM_LABELS columns are binary columns of class correspondence.  test_df should have the same structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change paths if needed\n",
    "train_df = pd.read_csv(os.path.join(corpus_dir, \"train.csv\"), encoding=\"utf-8\")\n",
    "dev_df = pd.read_csv(os.path.join(corpus_dir, \"dev.csv\"), encoding=\"utf-8\")\n",
    "\n",
    "train_examples = create_examples(train_df)\n",
    "eval_examples = create_examples(dev_df)\n",
    "# Model is saved and evaluated every epoch. It might be too frequent, change it.\n",
    "num_train_steps = int(len(train_examples) / batch_size * num_train_epochs)\n",
    "num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "num_steps_in_epoch = int(len(train_examples) / batch_size * num_train_epochs) // num_train_epochs\n",
    "save_checkpoints_steps = num_steps_in_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'results/', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 50, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f17db38cb70>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Creating tokenizer\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file=bert_vocab_path, do_lower_case=True)\n",
    "# Definition of estimator's config\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=output_dir,\n",
    "    save_summary_steps=save_summary_steps,\n",
    "    keep_checkpoint_max=1,\n",
    "    save_checkpoints_steps=save_checkpoints_steps)\n",
    "# Loading config of pretrained Bert model\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_path)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=NUM_LABELS ,\n",
    "    init_checkpoint=bert_init_chkpnt_path,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=False,\n",
    "    use_one_hot_embeddings=False)\n",
    "\n",
    "estimator = get_estimator(model_fn=model_fn, run_config=run_config, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 1627\n",
      "INFO:tensorflow:  Batch size = 32\n",
      "INFO:tensorflow:  Num steps = 254\n",
      "Beginning Training!\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 50 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/dask/dataframe/utils.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tlenusik/tweets_classification_smm4h/bert/multilabel_bert.py:57: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(32, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(32, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into results/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6960664, step = 0\n",
      "INFO:tensorflow:accuracy = 0.43125, loss = 0.6960664\n",
      "INFO:tensorflow:accuracy = 0.584375, loss = 0.6169146 (12.620 sec)\n",
      "INFO:tensorflow:accuracy = 0.6625, loss = 0.44438583 (6.415 sec)\n",
      "INFO:tensorflow:accuracy = 0.69375, loss = 0.45706087 (6.414 sec)\n",
      "INFO:tensorflow:accuracy = 0.71375, loss = 0.41767502 (6.412 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 50 into results/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-19-21:06:55\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-50\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.7875, loss = 0.4404083\n",
      "INFO:tensorflow:accuracy = 0.809375, loss = 0.41624135 (0.781 sec)\n",
      "INFO:tensorflow:accuracy = 0.8333333, loss = 0.33843204 (0.356 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-19-21:07:08\n",
      "INFO:tensorflow:Saving dict for global step 50: 0 = 0.7005871, 1 = 0.82046175, 2 = 0.8271475, 3 = 0.8228012, 4 = 0.5821006, eval_loss = 0.38929996, global_step = 50, loss = 0.38648275\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: results/model.ckpt-50\n",
      "INFO:tensorflow:accuracy = 0.73541665, loss = 0.3871069 (42.362 sec)\n",
      "INFO:tensorflow:accuracy = 0.7491071, loss = 0.38356987 (6.413 sec)\n",
      "INFO:tensorflow:accuracy = 0.76640624, loss = 0.32135126 (6.416 sec)\n",
      "INFO:tensorflow:accuracy = 0.78333336, loss = 0.2673546 (6.417 sec)\n",
      "INFO:tensorflow:accuracy = 0.793125, loss = 0.31012303 (6.414 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 100 into results/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-19-21:08:03\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.8875, loss = 0.27499777\n",
      "INFO:tensorflow:accuracy = 0.8875, loss = 0.30696824 (0.792 sec)\n",
      "INFO:tensorflow:accuracy = 0.90208334, loss = 0.22732487 (0.355 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-19-21:08:17\n",
      "INFO:tensorflow:Saving dict for global step 100: 0 = 0.86790615, 1 = 0.8418259, 2 = 0.94911295, 3 = 0.9332964, 4 = 0.6005918, eval_loss = 0.27549225, global_step = 100, loss = 0.27197203\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: results/model.ckpt-100\n",
      "INFO:tensorflow:global_step/sec: 0.688416\n",
      "INFO:tensorflow:loss = 0.20447794, step = 100 (145.261 sec)\n",
      "INFO:tensorflow:accuracy = 0.8056818, loss = 0.20447794 (45.378 sec)\n",
      "INFO:tensorflow:accuracy = 0.81614584, loss = 0.21455467 (6.414 sec)\n",
      "INFO:tensorflow:accuracy = 0.8211538, loss = 0.29731753 (6.414 sec)\n",
      "INFO:tensorflow:accuracy = 0.8308036, loss = 0.14355846 (6.415 sec)\n",
      "INFO:tensorflow:accuracy = 0.83666664, loss = 0.22765847 (6.416 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 150 into results/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-19-21:09:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-150\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.93125, loss = 0.23160306\n",
      "INFO:tensorflow:accuracy = 0.903125, loss = 0.31585854 (0.813 sec)\n",
      "INFO:tensorflow:accuracy = 0.9145833, loss = 0.20147732 (0.356 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-19-21:09:24\n",
      "INFO:tensorflow:Saving dict for global step 150: 0 = 0.8972603, 1 = 0.9375, 2 = 0.95366484, 3 = 0.92762995, 4 = 0.7236194, eval_loss = 0.24839771, global_step = 150, loss = 0.24480164\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 150: results/model.ckpt-150\n",
      "INFO:tensorflow:accuracy = 0.8421875, loss = 0.1861467 (38.161 sec)\n",
      "INFO:tensorflow:accuracy = 0.8496324, loss = 0.11247331 (6.413 sec)\n",
      "INFO:tensorflow:accuracy = 0.85694444, loss = 0.12986834 (6.412 sec)\n",
      "INFO:tensorflow:accuracy = 0.86315787, loss = 0.10574099 (6.418 sec)\n",
      "INFO:tensorflow:accuracy = 0.868125, loss = 0.13266361 (6.416 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into results/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-19-21:10:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.9125, loss = 0.23071948\n",
      "INFO:tensorflow:accuracy = 0.9, loss = 0.27526197 (0.823 sec)\n",
      "INFO:tensorflow:accuracy = 0.9145833, loss = 0.19703779 (0.355 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-19-21:10:34\n",
      "INFO:tensorflow:Saving dict for global step 200: 0 = 0.90489244, 1 = 0.9608546, 2 = 0.96440244, 3 = 0.9362528, 4 = 0.81262326, eval_loss = 0.24157223, global_step = 200, loss = 0.23739655\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: results/model.ckpt-200\n",
      "INFO:tensorflow:global_step/sec: 0.746405\n",
      "INFO:tensorflow:loss = 0.13075578, step = 200 (133.975 sec)\n",
      "INFO:tensorflow:accuracy = 0.87261903, loss = 0.13075578 (44.495 sec)\n",
      "INFO:tensorflow:accuracy = 0.8767046, loss = 0.13022536 (6.412 sec)\n",
      "INFO:tensorflow:accuracy = 0.8804348, loss = 0.13363634 (6.411 sec)\n",
      "INFO:tensorflow:accuracy = 0.8846354, loss = 0.08351949 (6.415 sec)\n",
      "INFO:tensorflow:accuracy = 0.8875, loss = 0.14221933 (6.412 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 250 into results/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-19-21:11:42\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-250\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.89375, loss = 0.2550922\n",
      "INFO:tensorflow:accuracy = 0.890625, loss = 0.30315357 (0.810 sec)\n",
      "INFO:tensorflow:accuracy = 0.90416664, loss = 0.20493469 (0.355 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-19-21:11:53\n",
      "INFO:tensorflow:Saving dict for global step 250: 0 = 0.90724075, 1 = 0.96629506, 2 = 0.9618346, 3 = 0.93286526, 4 = 0.79511833, eval_loss = 0.24118547, global_step = 250, loss = 0.23615332\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 250: results/model.ckpt-250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:accuracy = 0.8908654, loss = 0.1188524 (53.453 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 254 into results/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-19-21:12:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-254\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.89375, loss = 0.25370747\n",
      "INFO:tensorflow:accuracy = 0.890625, loss = 0.30256602 (0.806 sec)\n",
      "INFO:tensorflow:accuracy = 0.90416664, loss = 0.20476274 (0.357 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-19-21:12:28\n",
      "INFO:tensorflow:Saving dict for global step 254: 0 = 0.90753424, 1 = 0.96616244, 2 = 0.9616012, 3 = 0.932742, 4 = 0.7943787, eval_loss = 0.24099253, global_step = 254, loss = 0.23597877\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 254: results/model.ckpt-254\n",
      "INFO:tensorflow:Loss for final step: 0.09665498.\n",
      "Training took time  0:07:41.530105\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-19-21:12:33\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-254\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.89375, loss = 0.25370747\n",
      "INFO:tensorflow:accuracy = 0.890625, loss = 0.30256602 (0.821 sec)\n",
      "INFO:tensorflow:accuracy = 0.90416664, loss = 0.20476274 (0.355 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-19-21:12:36\n",
      "INFO:tensorflow:Saving dict for global step 254: 0 = 0.90753424, 1 = 0.96616244, 2 = 0.9616012, 3 = 0.932742, 4 = 0.7943787, eval_loss = 0.24099253, global_step = 254, loss = 0.23597877\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 254: results/model.ckpt-254\n",
      "INFO:tensorflow:***** Eval results *****\n",
      "INFO:tensorflow:  0 = 0.90753424\n",
      "INFO:tensorflow:  1 = 0.96616244\n",
      "INFO:tensorflow:  2 = 0.9616012\n",
      "INFO:tensorflow:  3 = 0.932742\n",
      "INFO:tensorflow:  4 = 0.7943787\n",
      "INFO:tensorflow:  eval_loss = 0.24099253\n",
      "INFO:tensorflow:  global_step = 254\n",
      "INFO:tensorflow:  loss = 0.23597877\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "eval_steps = None\n",
    "\n",
    "train_and_evaluate(train_examples, eval_examples, max_seq_length, estimator, tokenizer, batch_size, eval_steps,\n",
    "                   num_train_steps, output_dir, num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting class probabilities\n",
    "The resulting file with test labels is saved at \"output_dir/predicted_proba_filename\" (path parameters are initialized at \"Parameters\" section). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining documents to predict labels for manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ['This is some string',\n",
    "       'This is another string']\n",
    "test_df = pd.DataFrame(strings, columns =[text_column_name], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading test set from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'results/', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f163c3ed860>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "train_examples = None\n",
    "num_train_steps = None\n",
    "num_warmup_steps = None\n",
    "save_checkpoints_steps = 1000\n",
    "\n",
    "# Creating tokenizer\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file=bert_vocab_path, do_lower_case=True)\n",
    "# Definition of estimator's config\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=output_dir,\n",
    "    save_summary_steps=save_summary_steps,\n",
    "    keep_checkpoint_max=1,\n",
    "    save_checkpoints_steps=save_checkpoints_steps)\n",
    "# Loading config of pretrained Bert model\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_path)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=NUM_LABELS ,\n",
    "    init_checkpoint=bert_init_chkpnt_path,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=False,\n",
    "    use_one_hot_embeddings=False)\n",
    "\n",
    "estimator = get_estimator(model_fn=model_fn, run_config=run_config, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change path if needed\n",
    "test_df = pd.read_csv(os.path.join(corpus_dir, \"test.csv\"), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Predictions!\n",
      "Prediction took time  0:00:00.000154\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-254\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>EF</th>\n",
       "      <th>INF</th>\n",
       "      <th>ADR</th>\n",
       "      <th>DI</th>\n",
       "      <th>Finding</th>\n",
       "      <th>annotation</th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>p_label_1</th>\n",
       "      <th>p_label_2</th>\n",
       "      <th>p_label_3</th>\n",
       "      <th>p_label_4</th>\n",
       "      <th>p_label_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Стала нервной, капризной, чуть что -сразу визг...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DI[3]|Finding[1]</td>\n",
       "      <td>252298</td>\n",
       "      <td>4</td>\n",
       "      <td>0.138464</td>\n",
       "      <td>0.047360</td>\n",
       "      <td>0.374648</td>\n",
       "      <td>0.949777</td>\n",
       "      <td>0.238476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>После недельного приема дочурка легче стала ос...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EF[2]</td>\n",
       "      <td>252298</td>\n",
       "      <td>7</td>\n",
       "      <td>0.966925</td>\n",
       "      <td>0.040048</td>\n",
       "      <td>0.058967</td>\n",
       "      <td>0.198397</td>\n",
       "      <td>0.087818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Очень радует то, что таблетки не горькие, я ра...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>252298</td>\n",
       "      <td>8</td>\n",
       "      <td>0.070150</td>\n",
       "      <td>0.017458</td>\n",
       "      <td>0.028494</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>0.060750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>И так с появление ребенка в нашей семье и част...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DI[1]</td>\n",
       "      <td>2457636</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036640</td>\n",
       "      <td>0.023940</td>\n",
       "      <td>0.015324</td>\n",
       "      <td>0.941991</td>\n",
       "      <td>0.047814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Болезнь немного отступала, но потом с новой си...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>INF[3]|DI[2]</td>\n",
       "      <td>2457636</td>\n",
       "      <td>5</td>\n",
       "      <td>0.059428</td>\n",
       "      <td>0.910076</td>\n",
       "      <td>0.046749</td>\n",
       "      <td>0.824391</td>\n",
       "      <td>0.087311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  EF  INF  ADR  DI  \\\n",
       "0  Стала нервной, капризной, чуть что -сразу визг...   0    0    0   1   \n",
       "1  После недельного приема дочурка легче стала ос...   1    0    0   0   \n",
       "2  Очень радует то, что таблетки не горькие, я ра...   0    0    0   0   \n",
       "3  И так с появление ребенка в нашей семье и част...   0    0    0   1   \n",
       "4  Болезнь немного отступала, но потом с новой си...   0    1    0   1   \n",
       "\n",
       "   Finding        annotation  review_id  sentence_id  p_label_1  p_label_2  \\\n",
       "0        1  DI[3]|Finding[1]     252298            4   0.138464   0.047360   \n",
       "1        0             EF[2]     252298            7   0.966925   0.040048   \n",
       "2        0           NEUTRAL     252298            8   0.070150   0.017458   \n",
       "3        0             DI[1]    2457636            2   0.036640   0.023940   \n",
       "4        0      INF[3]|DI[2]    2457636            5   0.059428   0.910076   \n",
       "\n",
       "   p_label_3  p_label_4  p_label_5  \n",
       "0   0.374648   0.949777   0.238476  \n",
       "1   0.058967   0.198397   0.087818  \n",
       "2   0.028494   0.022673   0.060750  \n",
       "3   0.015324   0.941991   0.047814  \n",
       "4   0.046749   0.824391   0.087311  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = predict(test_df, estimator, tokenizer, max_seq_length, num_labels=NUM_LABELS)\n",
    "\n",
    "resulting_df = test_df[text_column_name]\n",
    "resulting_df = pd.concat([test_df, output_df], axis=1)\n",
    "resulting_df.to_csv(os.path.join(output_dir, predicted_proba_filename), index=False)\n",
    "\n",
    "resulting_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
