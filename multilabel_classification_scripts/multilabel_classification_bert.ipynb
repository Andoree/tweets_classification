{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, you need to pull:\n",
    "\n",
    "https://github.com/google-research/bert\n",
    "\n",
    "And add bert_preprocessing.py and multilabel_bert.py script from to the pulled directory (put it in the same directory with modeling.py, optimization.py, tokenization.py):\n",
    "\n",
    "https://github.com/Andoree/tweets_classification/tree/master/multilabel_classification_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import modeling\n",
    "import optimization\n",
    "import tokenization\n",
    "from bert_preprocessing import create_examples, file_based_convert_examples_to_features, \\\n",
    "    convert_examples_to_features\n",
    "from multilabel_bert import file_based_input_fn_builder, create_model, model_fn_builder, \\\n",
    "input_fn_builder, create_output, predict, get_estimator, train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "# Setting CUDA device\n",
    "%env CUDA_VISIBLE_DEVICES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dir  = r\"otzovik_csvs/fold_0/\"\n",
    "bert_vocab_path = r\"/home/tlenusik/DATA/pretrained_models/multilingual_russian_reviews_finetuned/vocab.txt\"\n",
    "# Change checkpoint if you want to use multilanguage Bert model that is finetuned on another dataset.\n",
    "bert_init_chkpnt_path = r\"/home/tlenusik/DATA/pretrained_models/multilingual_russian_reviews_finetuned/bert_model.ckpt\"\n",
    "bert_config_path =  r\"/home/tlenusik/DATA/pretrained_models/multilingual_russian_reviews_finetuned/bert_config.json\"\n",
    "batch_size = 32\n",
    "num_train_epochs = 5\n",
    "warmup_proportion = 0.1\n",
    "max_seq_length = 128\n",
    "learning_rate = 2e-5\n",
    "save_summary_steps = 500\n",
    "output_dir = r\"results/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "predicted_proba_filename = \"predicted_labels.csv\"\n",
    "\n",
    "# Number of classes\n",
    "NUM_LABELS = 5\n",
    "# The column with this name must exist in test data\n",
    "text_column_name = 'sentences'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation\n",
    "Validation loss and accuracy for all classes is saved in \"output_dir/eval_results.txt\" (path parameters are initialized at \"Parameters\" section). \n",
    "\n",
    "The first column of csv file must contain document's text. The next NUM_LABELS columns are binary columns of class correspondence.  test_df should have the same structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change paths if needed\n",
    "train_df = pd.read_csv(os.path.join(corpus_dir, \"train.csv\"), encoding=\"utf-8\")\n",
    "dev_df = pd.read_csv(os.path.join(corpus_dir, \"dev.csv\"), encoding=\"utf-8\")\n",
    "\n",
    "train_examples = create_examples(train_df)\n",
    "eval_examples = create_examples(dev_df)\n",
    "# Model is saved and evaluated every epoch. It might be too frequent, change it.\n",
    "num_train_steps = int(len(train_examples) / batch_size * num_train_epochs)\n",
    "num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "num_steps_in_epoch = int(len(train_examples) / batch_size * num_train_epochs) // num_train_epochs\n",
    "save_checkpoints_steps = num_steps_in_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'results/', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 50, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faba43baba8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Creating tokenizer\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file=bert_vocab_path, do_lower_case=True)\n",
    "# Definition of estimator's config\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=output_dir,\n",
    "    save_summary_steps=save_summary_steps,\n",
    "    keep_checkpoint_max=1,\n",
    "    save_checkpoints_steps=save_checkpoints_steps)\n",
    "# Loading config of pretrained Bert model\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_path)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=NUM_LABELS ,\n",
    "    init_checkpoint=bert_init_chkpnt_path,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=False,\n",
    "    use_one_hot_embeddings=False)\n",
    "\n",
    "estimator = get_estimator(model_fn=model_fn, run_config=run_config, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 1627\n",
      "INFO:tensorflow:  Batch size = 32\n",
      "INFO:tensorflow:  Num steps = 254\n",
      "Beginning Training!\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 50 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "Training took time  0:00:00.004914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/dask/dataframe/utils.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tlenusik/tweets_classification_smm4h/bert/multilabel_bert.py:57: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-20-14:02:51\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-254\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.9, loss = 0.28989163\n",
      "INFO:tensorflow:accuracy = 0.90625, loss = 0.25048473 (0.793 sec)\n",
      "INFO:tensorflow:accuracy = 0.9125, loss = 0.20238435 (0.355 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-20-14:02:55\n",
      "INFO:tensorflow:Saving dict for global step 254: 0 = 0.91536206, 1 = 0.97637993, 2 = 0.9588002, 3 = 0.93323475, 4 = 0.8002959, eval_loss = 0.23611209, global_step = 254, loss = 0.2312926\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 254: results/model.ckpt-254\n",
      "INFO:tensorflow:***** Eval results *****\n",
      "INFO:tensorflow:  0 = 0.91536206\n",
      "INFO:tensorflow:  1 = 0.97637993\n",
      "INFO:tensorflow:  2 = 0.9588002\n",
      "INFO:tensorflow:  3 = 0.93323475\n",
      "INFO:tensorflow:  4 = 0.8002959\n",
      "INFO:tensorflow:  eval_loss = 0.23611209\n",
      "INFO:tensorflow:  global_step = 254\n",
      "INFO:tensorflow:  loss = 0.2312926\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "eval_steps = None\n",
    "\n",
    "train_and_evaluate(train_examples, eval_examples, max_seq_length, estimator, tokenizer, batch_size, eval_steps,\n",
    "                   num_train_steps, output_dir, num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting class probabilities\n",
    "The resulting file with test labels is saved at \"output_dir/predicted_proba_filename\" (path parameters are initialized at \"Parameters\" section). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining documents to predict labels for manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ['This is some string',\n",
    "       'This is another string']\n",
    "test_df = pd.DataFrame(strings, columns =[text_column_name], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading test set from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'results/', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faba43ba748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "train_examples = None\n",
    "num_train_steps = None\n",
    "num_warmup_steps = None\n",
    "save_checkpoints_steps = 1000\n",
    "\n",
    "# Creating tokenizer\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file=bert_vocab_path, do_lower_case=True)\n",
    "# Definition of estimator's config\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=output_dir,\n",
    "    save_summary_steps=save_summary_steps,\n",
    "    keep_checkpoint_max=1,\n",
    "    save_checkpoints_steps=save_checkpoints_steps)\n",
    "# Loading config of pretrained Bert model\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_path)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=NUM_LABELS ,\n",
    "    init_checkpoint=bert_init_chkpnt_path,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=False,\n",
    "    use_one_hot_embeddings=False)\n",
    "\n",
    "estimator = get_estimator(model_fn=model_fn, run_config=run_config, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change path if needed\n",
    "test_df = pd.read_csv(os.path.join(corpus_dir, \"test.csv\"), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Predictions!\n",
      "Prediction took time  0:00:00.000139\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-254\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>EF</th>\n",
       "      <th>INF</th>\n",
       "      <th>ADR</th>\n",
       "      <th>DI</th>\n",
       "      <th>Finding</th>\n",
       "      <th>annotation</th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>p_label_1</th>\n",
       "      <th>p_label_2</th>\n",
       "      <th>p_label_3</th>\n",
       "      <th>p_label_4</th>\n",
       "      <th>p_label_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Стала нервной, капризной, чуть что -сразу визг...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DI[3]|Finding[1]</td>\n",
       "      <td>252298</td>\n",
       "      <td>4</td>\n",
       "      <td>0.450735</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>0.133663</td>\n",
       "      <td>0.987296</td>\n",
       "      <td>0.205825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>После недельного приема дочурка легче стала ос...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EF[2]</td>\n",
       "      <td>252298</td>\n",
       "      <td>7</td>\n",
       "      <td>0.972963</td>\n",
       "      <td>0.023177</td>\n",
       "      <td>0.062206</td>\n",
       "      <td>0.538695</td>\n",
       "      <td>0.067674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Очень радует то, что таблетки не горькие, я ра...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>252298</td>\n",
       "      <td>8</td>\n",
       "      <td>0.074273</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.036345</td>\n",
       "      <td>0.019955</td>\n",
       "      <td>0.065263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>И так с появление ребенка в нашей семье и част...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DI[1]</td>\n",
       "      <td>2457636</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036110</td>\n",
       "      <td>0.023751</td>\n",
       "      <td>0.009731</td>\n",
       "      <td>0.945586</td>\n",
       "      <td>0.035801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Болезнь немного отступала, но потом с новой си...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>INF[3]|DI[2]</td>\n",
       "      <td>2457636</td>\n",
       "      <td>5</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>0.940838</td>\n",
       "      <td>0.051291</td>\n",
       "      <td>0.916195</td>\n",
       "      <td>0.097008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  EF  INF  ADR  DI  \\\n",
       "0  Стала нервной, капризной, чуть что -сразу визг...   0    0    0   1   \n",
       "1  После недельного приема дочурка легче стала ос...   1    0    0   0   \n",
       "2  Очень радует то, что таблетки не горькие, я ра...   0    0    0   0   \n",
       "3  И так с появление ребенка в нашей семье и част...   0    0    0   1   \n",
       "4  Болезнь немного отступала, но потом с новой си...   0    1    0   1   \n",
       "\n",
       "   Finding        annotation  review_id  sentence_id  p_label_1  p_label_2  \\\n",
       "0        1  DI[3]|Finding[1]     252298            4   0.450735   0.098715   \n",
       "1        0             EF[2]     252298            7   0.972963   0.023177   \n",
       "2        0           NEUTRAL     252298            8   0.074273   0.011486   \n",
       "3        0             DI[1]    2457636            2   0.036110   0.023751   \n",
       "4        0      INF[3]|DI[2]    2457636            5   0.095751   0.940838   \n",
       "\n",
       "   p_label_3  p_label_4  p_label_5  \n",
       "0   0.133663   0.987296   0.205825  \n",
       "1   0.062206   0.538695   0.067674  \n",
       "2   0.036345   0.019955   0.065263  \n",
       "3   0.009731   0.945586   0.035801  \n",
       "4   0.051291   0.916195   0.097008  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = predict(test_df, estimator, tokenizer, max_seq_length, num_labels=NUM_LABELS)\n",
    "\n",
    "resulting_df = test_df[text_column_name]\n",
    "resulting_df = pd.concat([test_df, output_df], axis=1)\n",
    "resulting_df.to_csv(os.path.join(output_dir, predicted_proba_filename), index=False)\n",
    "\n",
    "resulting_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "METRICS = {\"Precision\": precision_score, \"Recall\": recall_score,\n",
    "           \"F-score\": f1_score, }\n",
    "threshold=0.5\n",
    "average='binary'\n",
    "pos_label=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 EF\n",
      "\tPrecision : 0.7974683544303798\n",
      "\tRecall : 0.7682926829268293\n",
      "\tF-score : 0.782608695652174\n",
      "1 INF\n",
      "\tPrecision : 0.74\n",
      "\tRecall : 0.7551020408163265\n",
      "\tF-score : 0.7474747474747474\n",
      "2 ADR\n",
      "\tPrecision : 0.7866666666666666\n",
      "\tRecall : 0.6704545454545454\n",
      "\tF-score : 0.7239263803680981\n",
      "3 DI\n",
      "\tPrecision : 0.7571428571428571\n",
      "\tRecall : 0.9244186046511628\n",
      "\tF-score : 0.8324607329842932\n",
      "4 Finding\n",
      "\tPrecision : 0.7857142857142857\n",
      "\tRecall : 0.25\n",
      "\tF-score : 0.37931034482758624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a, int64b, int64a, int64b, int64a, int64b, int64a, int64b, int64a, int64b, int64"
     ]
    }
   ],
   "source": [
    "predicted_probs_pos_end = resulting_df.shape[1]\n",
    "predicted_probs_pos_start = predicted_probs_pos_end - NUM_LABELS\n",
    "columns = resulting_df.columns\n",
    "labels = columns[1: 1 + NUM_LABELS]\n",
    "results_numpy = resulting_df.values.transpose()\n",
    "all_true_labels = results_numpy[1: 1 + NUM_LABELS].astype(int)\n",
    "all_pred_probs = results_numpy[predicted_probs_pos_start: predicted_probs_pos_end]\n",
    "all_pred_labels = (all_pred_probs >= threshold).astype(int)\n",
    "for i in range(NUM_LABELS):\n",
    "    class_true_labels = all_true_labels[i]\n",
    "    class_pred_labels = all_pred_labels[i]\n",
    "    label_name = labels[i]\n",
    "    print(i, label_name)\n",
    "    for metric_name, metric in METRICS.items():\n",
    "        score = metric(y_true=class_true_labels, y_pred=class_pred_labels, labels=labels, )\n",
    "        print(f\"\\t{metric_name} : {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
