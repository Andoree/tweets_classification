{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before running this notebook, you need to pull:\n",
      "\n",
      "https://github.com/google-research/bert\n",
      "\n",
      "And add bert_preprocessing.py and multilabel_bert.py script from to the pulled directory (put it in the same directory with modeling.py, optimization.py, tokenization.py):\n",
      "\n",
      "https://github.com/Andoree/tweets_classification/tree/master/multilabel_classification_scripts"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "from datetime import datetime\n",
      "import os\n",
      "\n",
      "import pandas as pd\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import modeling\n",
      "import optimization\n",
      "import tokenization\n",
      "from bert_preprocessing import create_examples, file_based_convert_examples_to_features, \\\n",
      "    convert_examples_to_features\n",
      "from multilabel_bert import file_based_input_fn_builder, create_model, model_fn_builder, \\\n",
      "input_fn_builder, create_output, predict, get_estimator, train_and_evaluate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Setting CUDA device\n",
      "%env CUDA_VISIBLE_DEVICES = 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "env: CUDA_VISIBLE_DEVICES=2\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus_dir  = r\"otzovik_csvs/fold_0/\"\n",
      "bert_vocab_path = r\"/home/tlenusik/DATA/pretrained_models/multilingual_russian_reviews_finetuned/vocab.txt\"\n",
      "# Change checkpoint if you want to use multilanguage Bert model that is finetuned on another dataset.\n",
      "bert_init_chkpnt_path = r\"/home/tlenusik/DATA/pretrained_models/multilingual_russian_reviews_finetuned/bert_model.ckpt\"\n",
      "bert_config_path =  r\"/home/tlenusik/DATA/pretrained_models/multilingual_russian_reviews_finetuned/bert_config.json\"\n",
      "batch_size = 32\n",
      "num_train_epochs = 5\n",
      "warmup_proportion = 0.1\n",
      "max_seq_length = 128\n",
      "learning_rate = 2e-5\n",
      "save_summary_steps = 500\n",
      "output_dir = r\"results/\"\n",
      "if not os.path.exists(output_dir):\n",
      "    os.makedirs(output_dir)\n",
      "predicted_proba_filename = \"predicted_labels.csv\"\n",
      "\n",
      "# Number of classes\n",
      "NUM_LABELS = 5\n",
      "# The column with this name must exist in test data\n",
      "text_column_name = 'sentences'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Training and evaluation\n",
      "Validation loss and accuracy for all classes is saved in \"output_dir/eval_results.txt\" (path parameters are initialized at \"Parameters\" section). \n",
      "\n",
      "The first column of csv file must contain document's text. The next NUM_LABELS columns are binary columns of class correspondence.  test_df should have the same structure."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Change paths if needed\n",
      "train_df = pd.read_csv(os.path.join(corpus_dir, \"train.csv\"), encoding=\"utf-8\")\n",
      "dev_df = pd.read_csv(os.path.join(corpus_dir, \"dev.csv\"), encoding=\"utf-8\")\n",
      "\n",
      "train_examples = create_examples(train_df)\n",
      "eval_examples = create_examples(dev_df)\n",
      "# Model is saved and evaluated every epoch. It might be too frequent, change it.\n",
      "num_train_steps = int(len(train_examples) / batch_size * num_train_epochs)\n",
      "num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
      "num_steps_in_epoch = int(len(train_examples) / batch_size * num_train_epochs) // num_train_epochs\n",
      "save_checkpoints_steps = num_steps_in_epoch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creating tokenizer\n",
      "tokenizer = tokenization.FullTokenizer(\n",
      "    vocab_file=bert_vocab_path, do_lower_case=True)\n",
      "# Definition of estimator's config\n",
      "run_config = tf.estimator.RunConfig(\n",
      "    model_dir=output_dir,\n",
      "    save_summary_steps=save_summary_steps,\n",
      "    keep_checkpoint_max=1,\n",
      "    save_checkpoints_steps=save_checkpoints_steps)\n",
      "# Loading config of pretrained Bert model\n",
      "bert_config = modeling.BertConfig.from_json_file(bert_config_path)\n",
      "\n",
      "model_fn = model_fn_builder(\n",
      "    bert_config=bert_config,\n",
      "    num_labels=NUM_LABELS ,\n",
      "    init_checkpoint=bert_init_chkpnt_path,\n",
      "    learning_rate=learning_rate,\n",
      "    num_train_steps=num_train_steps,\n",
      "    num_warmup_steps=num_warmup_steps,\n",
      "    use_tpu=False,\n",
      "    use_one_hot_embeddings=False)\n",
      "\n",
      "estimator = get_estimator(model_fn=model_fn, run_config=run_config, batch_size=batch_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Using config: {'_model_dir': 'results/', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 50, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
        "graph_options {\n",
        "  rewrite_options {\n",
        "    meta_optimizer_iterations: ONE\n",
        "  }\n",
        "}\n",
        ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe0906fabe0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf.logging.set_verbosity(tf.logging.INFO)\n",
      "\n",
      "eval_steps = None\n",
      "\n",
      "train_and_evaluate(train_examples, eval_examples, max_seq_length, estimator, tokenizer, batch_size, eval_steps,\n",
      "                   num_train_steps, output_dir, num_labels=NUM_LABELS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:***** Running training *****\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:  Num examples = 1627\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:  Batch size = 32\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:  Num steps = 254\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Beginning Training!\n",
        "INFO:tensorflow:Not using Distribute Coordinator.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 50 or save_checkpoints_secs None.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training took time  0:00:00.005761\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python3.6/dist-packages/dask/dataframe/utils.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
        "  import pandas.util.testing as tm\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "WARNING:tensorflow:From /home/tlenusik/tweets_classification_smm4h/bert/multilabel_bert.py:57: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
        "Instructions for updating:\n",
        "Use `tf.data.experimental.map_and_batch(...)`.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Calling model_fn.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:**** Trainable Variables ****\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Done calling model_fn.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Starting evaluation at 2020-05-20-13:59:46\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Graph was finalized.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Restoring parameters from results/model.ckpt-254\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Running local_init_op.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Done running local_init_op.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:accuracy = 0.9, loss = 0.28989163\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:accuracy = 0.90625, loss = 0.25048473 (0.780 sec)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:accuracy = 0.9125, loss = 0.20238435 (0.355 sec)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Finished evaluation at 2020-05-20-13:59:51\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Saving dict for global step 254: 0 = 0.91536206, 1 = 0.97637993, 2 = 0.9588002, 3 = 0.93323475, 4 = 0.8002959, eval_loss = 0.23611209, global_step = 254, loss = 0.2312926\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 254: results/model.ckpt-254\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:***** Eval results *****\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:  0 = 0.91536206\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:  1 = 0.97637993\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:  2 = 0.9588002\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:  3 = 0.93323475\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:  4 = 0.8002959\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:  eval_loss = 0.23611209\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:  global_step = 254\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:  loss = 0.2312926\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Predicting class probabilities\n",
      "The resulting file with test labels is saved at \"output_dir/predicted_proba_filename\" (path parameters are initialized at \"Parameters\" section). "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Defining documents to predict labels for manually"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "strings = ['This is some string',\n",
      "       'This is another string']\n",
      "test_df = pd.DataFrame(strings, columns =[text_column_name], )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Loading test set from csv file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_examples = None\n",
      "num_train_steps = None\n",
      "num_warmup_steps = None\n",
      "save_checkpoints_steps = 1000\n",
      "\n",
      "# Creating tokenizer\n",
      "tokenizer = tokenization.FullTokenizer(\n",
      "    vocab_file=bert_vocab_path, do_lower_case=True)\n",
      "# Definition of estimator's config\n",
      "run_config = tf.estimator.RunConfig(\n",
      "    model_dir=output_dir,\n",
      "    save_summary_steps=save_summary_steps,\n",
      "    keep_checkpoint_max=1,\n",
      "    save_checkpoints_steps=save_checkpoints_steps)\n",
      "# Loading config of pretrained Bert model\n",
      "bert_config = modeling.BertConfig.from_json_file(bert_config_path)\n",
      "\n",
      "model_fn = model_fn_builder(\n",
      "    bert_config=bert_config,\n",
      "    num_labels=NUM_LABELS ,\n",
      "    init_checkpoint=bert_init_chkpnt_path,\n",
      "    learning_rate=learning_rate,\n",
      "    num_train_steps=num_train_steps,\n",
      "    num_warmup_steps=num_warmup_steps,\n",
      "    use_tpu=False,\n",
      "    use_one_hot_embeddings=False)\n",
      "\n",
      "estimator = get_estimator(model_fn=model_fn, run_config=run_config, batch_size=batch_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Using config: {'_model_dir': 'results/', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
        "graph_options {\n",
        "  rewrite_options {\n",
        "    meta_optimizer_iterations: ONE\n",
        "  }\n",
        "}\n",
        ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe0906fa780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Change path if needed\n",
      "test_df = pd.read_csv(os.path.join(corpus_dir, \"test.csv\"), encoding=\"utf-8\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_df = predict(test_df, estimator, tokenizer, max_seq_length, num_labels=NUM_LABELS)\n",
      "\n",
      "resulting_df = test_df[text_column_name]\n",
      "resulting_df = pd.concat([test_df, output_df], axis=1)\n",
      "resulting_df.to_csv(os.path.join(output_dir, predicted_proba_filename), index=False)\n",
      "\n",
      "resulting_df.head()"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Beginning Predictions!\n",
        "Prediction took time  0:00:00.000180\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Calling model_fn.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:**** Trainable Variables ****\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 5), dtype=float32)\n",
        "INFO:tensorflow:Done calling model_fn.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Graph was finalized.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Restoring parameters from results/model.ckpt-254\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Running local_init_op.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INFO:tensorflow:Done running local_init_op.\n"
       ]
      },
      {
       "html": [
        "<div>\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>sentences</th>\n",
        "      <th>EF</th>\n",
        "      <th>INF</th>\n",
        "      <th>ADR</th>\n",
        "      <th>DI</th>\n",
        "      <th>Finding</th>\n",
        "      <th>annotation</th>\n",
        "      <th>review_id</th>\n",
        "      <th>sentence_id</th>\n",
        "      <th>p_label_1</th>\n",
        "      <th>p_label_2</th>\n",
        "      <th>p_label_3</th>\n",
        "      <th>p_label_4</th>\n",
        "      <th>p_label_5</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>\u0421\u0442\u0430\u043b\u0430 \u043d\u0435\u0440\u0432\u043d\u043e\u0439, \u043a\u0430\u043f\u0440\u0438\u0437\u043d\u043e\u0439, \u0447\u0443\u0442\u044c \u0447\u0442\u043e -\u0441\u0440\u0430\u0437\u0443 \u0432\u0438\u0437\u0433...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>DI[3]|Finding[1]</td>\n",
        "      <td>252298</td>\n",
        "      <td>4</td>\n",
        "      <td>0.450735</td>\n",
        "      <td>0.098715</td>\n",
        "      <td>0.133663</td>\n",
        "      <td>0.987296</td>\n",
        "      <td>0.205825</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>\u041f\u043e\u0441\u043b\u0435 \u043d\u0435\u0434\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0440\u0438\u0435\u043c\u0430 \u0434\u043e\u0447\u0443\u0440\u043a\u0430 \u043b\u0435\u0433\u0447\u0435 \u0441\u0442\u0430\u043b\u0430 \u043e\u0441...</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>EF[2]</td>\n",
        "      <td>252298</td>\n",
        "      <td>7</td>\n",
        "      <td>0.972963</td>\n",
        "      <td>0.023177</td>\n",
        "      <td>0.062206</td>\n",
        "      <td>0.538695</td>\n",
        "      <td>0.067674</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>\u041e\u0447\u0435\u043d\u044c \u0440\u0430\u0434\u0443\u0435\u0442 \u0442\u043e, \u0447\u0442\u043e \u0442\u0430\u0431\u043b\u0435\u0442\u043a\u0438 \u043d\u0435 \u0433\u043e\u0440\u044c\u043a\u0438\u0435, \u044f \u0440\u0430...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>NEUTRAL</td>\n",
        "      <td>252298</td>\n",
        "      <td>8</td>\n",
        "      <td>0.074273</td>\n",
        "      <td>0.011486</td>\n",
        "      <td>0.036345</td>\n",
        "      <td>0.019955</td>\n",
        "      <td>0.065263</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>\u0418 \u0442\u0430\u043a \u0441 \u043f\u043e\u044f\u0432\u043b\u0435\u043d\u0438\u0435 \u0440\u0435\u0431\u0435\u043d\u043a\u0430 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0441\u0435\u043c\u044c\u0435 \u0438 \u0447\u0430\u0441\u0442...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>DI[1]</td>\n",
        "      <td>2457636</td>\n",
        "      <td>2</td>\n",
        "      <td>0.036110</td>\n",
        "      <td>0.023751</td>\n",
        "      <td>0.009731</td>\n",
        "      <td>0.945586</td>\n",
        "      <td>0.035801</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>\u0411\u043e\u043b\u0435\u0437\u043d\u044c \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u043e\u0442\u0441\u0442\u0443\u043f\u0430\u043b\u0430, \u043d\u043e \u043f\u043e\u0442\u043e\u043c \u0441 \u043d\u043e\u0432\u043e\u0439 \u0441\u0438...</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>INF[3]|DI[2]</td>\n",
        "      <td>2457636</td>\n",
        "      <td>5</td>\n",
        "      <td>0.095751</td>\n",
        "      <td>0.940838</td>\n",
        "      <td>0.051291</td>\n",
        "      <td>0.916195</td>\n",
        "      <td>0.097008</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "                                           sentences  EF  INF  ADR  DI  \\\n",
        "0  \u0421\u0442\u0430\u043b\u0430 \u043d\u0435\u0440\u0432\u043d\u043e\u0439, \u043a\u0430\u043f\u0440\u0438\u0437\u043d\u043e\u0439, \u0447\u0443\u0442\u044c \u0447\u0442\u043e -\u0441\u0440\u0430\u0437\u0443 \u0432\u0438\u0437\u0433...   0    0    0   1   \n",
        "1  \u041f\u043e\u0441\u043b\u0435 \u043d\u0435\u0434\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0440\u0438\u0435\u043c\u0430 \u0434\u043e\u0447\u0443\u0440\u043a\u0430 \u043b\u0435\u0433\u0447\u0435 \u0441\u0442\u0430\u043b\u0430 \u043e\u0441...   1    0    0   0   \n",
        "2  \u041e\u0447\u0435\u043d\u044c \u0440\u0430\u0434\u0443\u0435\u0442 \u0442\u043e, \u0447\u0442\u043e \u0442\u0430\u0431\u043b\u0435\u0442\u043a\u0438 \u043d\u0435 \u0433\u043e\u0440\u044c\u043a\u0438\u0435, \u044f \u0440\u0430...   0    0    0   0   \n",
        "3  \u0418 \u0442\u0430\u043a \u0441 \u043f\u043e\u044f\u0432\u043b\u0435\u043d\u0438\u0435 \u0440\u0435\u0431\u0435\u043d\u043a\u0430 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0441\u0435\u043c\u044c\u0435 \u0438 \u0447\u0430\u0441\u0442...   0    0    0   1   \n",
        "4  \u0411\u043e\u043b\u0435\u0437\u043d\u044c \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u043e\u0442\u0441\u0442\u0443\u043f\u0430\u043b\u0430, \u043d\u043e \u043f\u043e\u0442\u043e\u043c \u0441 \u043d\u043e\u0432\u043e\u0439 \u0441\u0438...   0    1    0   1   \n",
        "\n",
        "   Finding        annotation  review_id  sentence_id  p_label_1  p_label_2  \\\n",
        "0        1  DI[3]|Finding[1]     252298            4   0.450735   0.098715   \n",
        "1        0             EF[2]     252298            7   0.972963   0.023177   \n",
        "2        0           NEUTRAL     252298            8   0.074273   0.011486   \n",
        "3        0             DI[1]    2457636            2   0.036110   0.023751   \n",
        "4        0      INF[3]|DI[2]    2457636            5   0.095751   0.940838   \n",
        "\n",
        "   p_label_3  p_label_4  p_label_5  \n",
        "0   0.133663   0.987296   0.205825  \n",
        "1   0.062206   0.538695   0.067674  \n",
        "2   0.036345   0.019955   0.065263  \n",
        "3   0.009731   0.945586   0.035801  \n",
        "4   0.051291   0.916195   0.097008  "
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
      "\n",
      "METRICS = {\"Precision\": precision_score, \"Recall\": recall_score,\n",
      "           \"F-score\": f1_score, }\n",
      "threshold=0.5\n",
      "average='binary'\n",
      "pos_label=1\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted_probs_pos_end = resulting_df.shape[1]\n",
      "predicted_probs_pos_start = predicted_probs_pos_end - NUM_LABELS\n",
      "columns = resulting_df.columns\n",
      "labels = columns[1: 1 + NUM_LABELS]\n",
      "results_numpy = resulting_df.values.transpose()\n",
      "all_true_labels = results_numpy[1: 1 + NUM_LABELS]\n",
      "all_pred_probs = results_numpy[predicted_probs_pos_start: predicted_probs_pos_end]\n",
      "all_pred_labels = (all_pred_probs >= threshold).astype(np.int8)\n",
      "for i in range(NUM_LABELS):\n",
      "    class_true_labels = all_true_labels[i]\n",
      "    print(class_true_labels)\n",
      "    class_pred_labels = all_pred_labels[i]\n",
      "    sys.stderr.write(f\"a, {class_true_labels.dtype}\")\n",
      "    sys.stderr.write(f\"b, {class_pred_labels.dtype}\")\n",
      "    print(class_pred_labels)\n",
      "    label_name = labels[i]\n",
      "    print(i, label_name)\n",
      "    for metric_name, metric in METRICS.items():\n",
      "        score = metric(y_true=class_true_labels, y_pred=class_pred_labels, labels=labels, )\n",
      "        print(f\"\\t{metric_name} : {score}\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
        " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
        " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
        " 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
        " 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
        " 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 1\n",
        " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1\n",
        " 1 1 0 0 0 0 0 0]\n",
        "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
        " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
        " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
        " 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
        " 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
        " 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
        " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0\n",
        " 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
        " 0 1 1 0 0 0 0 0]\n",
        "0 EF\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "a, objectb, int8"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "Classification metrics can't handle a mix of unknown and binary targets",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-2d88c96f5064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMETRICS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_true_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_pred_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\t{metric_name} : {score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1270\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and binary targets"
       ]
      }
     ],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}
