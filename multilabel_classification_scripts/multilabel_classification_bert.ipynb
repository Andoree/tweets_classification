{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, you need to pull:\n",
    "\n",
    "https://github.com/google-research/bert\n",
    "\n",
    "And add bert_preprocessing.py and multilabel_bert.py script from to the pulled directory (put it in the same directory with modeling.py, optimization.py, tokenization.py):\n",
    "\n",
    "https://github.com/Andoree/tweets_classification/tree/master/multilabel_classification_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import modeling\n",
    "import optimization\n",
    "import tokenization\n",
    "from bert_preprocessing import create_examples, file_based_convert_examples_to_features, \\\n",
    "    convert_examples_to_features\n",
    "from multilabel_bert import file_based_input_fn_builder, create_model, model_fn_builder, \\\n",
    "input_fn_builder, create_output, predict, get_estimator, train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "# Setting CUDA device\n",
    "%env CUDA_VISIBLE_DEVICES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dir  = r\"otzovik_csvs/fold_0/\"\n",
    "bert_vocab_path = r\"/home/tlenusik/DATA/pretrained_models/multilingual_russian_reviews_finetuned/vocab.txt\"\n",
    "# Change checkpoint if you want to use multilanguage Bert model that is finetuned on another dataset.\n",
    "bert_init_chkpnt_path = r\"/home/tlenusik/DATA/pretrained_models/multilingual_russian_reviews_finetuned/bert_model.ckpt\"\n",
    "bert_config_path =  r\"/home/tlenusik/DATA/pretrained_models/multilingual_russian_reviews_finetuned/bert_config.json\"\n",
    "batch_size = 32\n",
    "num_train_epochs = 5\n",
    "warmup_proportion = 0.1\n",
    "max_seq_length = 128\n",
    "learning_rate = 2e-5\n",
    "save_summary_steps = 500\n",
    "output_dir = r\"results/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "predicted_proba_filename = \"predicted_labels.csv\"\n",
    "\n",
    "# Number of classes\n",
    "NUM_LABELS = 5\n",
    "# The column with this name must exist in test data\n",
    "text_column_name = 'sentences'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation\n",
    "Validation loss and accuracy for all classes is saved in \"output_dir/eval_results.txt\" (path parameters are initialized at \"Parameters\" section). \n",
    "\n",
    "The first column of csv file must contain document's text. The next NUM_LABELS columns are binary columns of class correspondence.  test_df should have the same structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change paths if needed\n",
    "train_df = pd.read_csv(os.path.join(corpus_dir, \"train.csv\"), encoding=\"utf-8\")\n",
    "dev_df = pd.read_csv(os.path.join(corpus_dir, \"dev.csv\"), encoding=\"utf-8\")\n",
    "\n",
    "train_examples = create_examples(train_df)\n",
    "eval_examples = create_examples(dev_df)\n",
    "# Model is saved and evaluated every epoch. It might be too frequent, change it.\n",
    "num_train_steps = int(len(train_examples) / batch_size * num_train_epochs)\n",
    "num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "num_steps_in_epoch = int(len(train_examples) / batch_size * num_train_epochs) // num_train_epochs\n",
    "save_checkpoints_steps = num_steps_in_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'results/', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 50, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc6f37afb70>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Creating tokenizer\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file=bert_vocab_path, do_lower_case=True)\n",
    "# Definition of estimator's config\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=output_dir,\n",
    "    save_summary_steps=save_summary_steps,\n",
    "    keep_checkpoint_max=1,\n",
    "    save_checkpoints_steps=save_checkpoints_steps)\n",
    "# Loading config of pretrained Bert model\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_path)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=NUM_LABELS ,\n",
    "    init_checkpoint=bert_init_chkpnt_path,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=False,\n",
    "    use_one_hot_embeddings=False)\n",
    "\n",
    "estimator = get_estimator(model_fn=model_fn, run_config=run_config, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 1627\n",
      "INFO:tensorflow:  Batch size = 32\n",
      "INFO:tensorflow:  Num steps = 254\n",
      "Beginning Training!\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 50 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/dask/dataframe/utils.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tlenusik/tweets_classification_smm4h/bert/multilabel_bert.py:57: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(32, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(32, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into results/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.7098543, step = 0\n",
      "INFO:tensorflow:accuracy = 0.425, loss = 0.7098543\n",
      "INFO:tensorflow:accuracy = 0.590625, loss = 0.64613503 (13.504 sec)\n",
      "INFO:tensorflow:accuracy = 0.6666667, loss = 0.44525427 (6.436 sec)\n",
      "INFO:tensorflow:accuracy = 0.70625, loss = 0.35905594 (6.420 sec)\n",
      "INFO:tensorflow:accuracy = 0.73, loss = 0.38003647 (6.426 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 50 into results/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-20-10:20:35\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-50\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.84375, loss = 0.35289398\n",
      "INFO:tensorflow:accuracy = 0.859375, loss = 0.34856588 (0.835 sec)\n",
      "INFO:tensorflow:accuracy = 0.875, loss = 0.27856705 (0.356 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-20-10:20:43\n",
      "INFO:tensorflow:Saving dict for global step 50: 0 = 0.85215276, 1 = 0.89556795, 2 = 0.929155, 3 = 0.8298842, 4 = 0.5443787, eval_loss = 0.32510117, global_step = 50, loss = 0.32327476\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: results/model.ckpt-50\n",
      "INFO:tensorflow:accuracy = 0.75104165, loss = 0.4138543 (39.762 sec)\n",
      "INFO:tensorflow:accuracy = 0.76875, loss = 0.31792307 (6.426 sec)\n",
      "INFO:tensorflow:accuracy = 0.78515625, loss = 0.2936074 (6.425 sec)\n",
      "INFO:tensorflow:accuracy = 0.8020833, loss = 0.22489507 (6.425 sec)\n",
      "INFO:tensorflow:accuracy = 0.810625, loss = 0.29172555 (6.429 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 100 into results/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-20-10:21:40\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.8875, loss = 0.30413848\n",
      "INFO:tensorflow:accuracy = 0.878125, loss = 0.3113672 (0.803 sec)\n",
      "INFO:tensorflow:accuracy = 0.89166665, loss = 0.23362377 (0.356 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-20-10:21:49\n",
      "INFO:tensorflow:Saving dict for global step 100: 0 = 0.8933464, 1 = 0.91295105, 2 = 0.9235529, 3 = 0.9039172, 4 = 0.71178496, eval_loss = 0.27598467, global_step = 100, loss = 0.2733876\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: results/model.ckpt-100\n",
      "INFO:tensorflow:global_step/sec: 0.712264\n",
      "INFO:tensorflow:loss = 0.2525412, step = 100 (140.398 sec)\n",
      "INFO:tensorflow:accuracy = 0.82045454, loss = 0.2525412 (42.144 sec)\n",
      "INFO:tensorflow:accuracy = 0.8307292, loss = 0.19486749 (6.423 sec)\n",
      "INFO:tensorflow:accuracy = 0.83990383, loss = 0.174566 (6.429 sec)\n",
      "INFO:tensorflow:accuracy = 0.846875, loss = 0.17502183 (6.423 sec)\n",
      "INFO:tensorflow:accuracy = 0.85375, loss = 0.15988363 (6.425 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 150 into results/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-20-10:22:47\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-150\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.9, loss = 0.23364735\n",
      "INFO:tensorflow:accuracy = 0.90625, loss = 0.22465885 (0.829 sec)\n",
      "INFO:tensorflow:accuracy = 0.91041666, loss = 0.22081721 (0.360 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-20-10:22:58\n",
      "INFO:tensorflow:Saving dict for global step 150: 0 = 0.91242653, 1 = 0.97226644, 2 = 0.970705, 3 = 0.9295393, 4 = 0.7936391, eval_loss = 0.23745969, global_step = 150, loss = 0.2338212\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 150: results/model.ckpt-150\n",
      "INFO:tensorflow:accuracy = 0.85976565, loss = 0.1809434 (40.141 sec)\n",
      "INFO:tensorflow:accuracy = 0.8672794, loss = 0.085126296 (6.425 sec)\n",
      "INFO:tensorflow:accuracy = 0.87430555, loss = 0.07824363 (6.427 sec)\n",
      "INFO:tensorflow:accuracy = 0.87960523, loss = 0.09745045 (6.425 sec)\n",
      "INFO:tensorflow:accuracy = 0.8853125, loss = 0.08610572 (6.426 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into results/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-20-10:23:53\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.90625, loss = 0.25593707\n",
      "INFO:tensorflow:accuracy = 0.9125, loss = 0.24122795 (0.793 sec)\n",
      "INFO:tensorflow:accuracy = 0.9166667, loss = 0.18928389 (0.356 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-20-10:24:03\n",
      "INFO:tensorflow:Saving dict for global step 200: 0 = 0.9188846, 1 = 0.97425693, 2 = 0.9687208, 3 = 0.92707556, 4 = 0.8328402, eval_loss = 0.23413448, global_step = 200, loss = 0.22970597\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: results/model.ckpt-200\n",
      "INFO:tensorflow:global_step/sec: 0.767453\n",
      "INFO:tensorflow:loss = 0.15131631, step = 200 (130.301 sec)\n",
      "INFO:tensorflow:accuracy = 0.88839287, loss = 0.15131631 (38.756 sec)\n",
      "INFO:tensorflow:accuracy = 0.89176136, loss = 0.12366451 (6.420 sec)\n",
      "INFO:tensorflow:accuracy = 0.8945652, loss = 0.13476263 (6.424 sec)\n",
      "INFO:tensorflow:accuracy = 0.8984375, loss = 0.09727291 (6.420 sec)\n",
      "INFO:tensorflow:accuracy = 0.90175, loss = 0.09400797 (6.423 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 250 into results/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-20-10:24:58\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-250\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.9, loss = 0.2918164\n",
      "INFO:tensorflow:accuracy = 0.90625, loss = 0.25221244 (0.815 sec)\n",
      "INFO:tensorflow:accuracy = 0.9125, loss = 0.20297413 (0.356 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-20-10:25:06\n",
      "INFO:tensorflow:Saving dict for global step 250: 0 = 0.9152642, 1 = 0.9762473, 2 = 0.9590336, 3 = 0.93292683, 4 = 0.80078906, eval_loss = 0.23663011, global_step = 250, loss = 0.23178579\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 250: results/model.ckpt-250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:accuracy = 0.90384614, loss = 0.15084578 (37.805 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 254 into results/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-20-10:25:32\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-254\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.9, loss = 0.28989163\n",
      "INFO:tensorflow:accuracy = 0.90625, loss = 0.25048473 (0.811 sec)\n",
      "INFO:tensorflow:accuracy = 0.9125, loss = 0.20238435 (0.356 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-20-10:25:40\n",
      "INFO:tensorflow:Saving dict for global step 254: 0 = 0.91536206, 1 = 0.97637993, 2 = 0.9588002, 3 = 0.93323475, 4 = 0.8002959, eval_loss = 0.23611209, global_step = 254, loss = 0.2312926\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 254: results/model.ckpt-254\n",
      "INFO:tensorflow:Loss for final step: 0.11949335.\n",
      "Training took time  0:07:18.232439\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-20-10:25:45\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-254\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.9, loss = 0.28989163\n",
      "INFO:tensorflow:accuracy = 0.90625, loss = 0.25048473 (0.819 sec)\n",
      "INFO:tensorflow:accuracy = 0.9125, loss = 0.20238435 (0.356 sec)\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-20-10:25:48\n",
      "INFO:tensorflow:Saving dict for global step 254: 0 = 0.91536206, 1 = 0.97637993, 2 = 0.9588002, 3 = 0.93323475, 4 = 0.8002959, eval_loss = 0.23611209, global_step = 254, loss = 0.2312926\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 254: results/model.ckpt-254\n",
      "INFO:tensorflow:***** Eval results *****\n",
      "INFO:tensorflow:  0 = 0.91536206\n",
      "INFO:tensorflow:  1 = 0.97637993\n",
      "INFO:tensorflow:  2 = 0.9588002\n",
      "INFO:tensorflow:  3 = 0.93323475\n",
      "INFO:tensorflow:  4 = 0.8002959\n",
      "INFO:tensorflow:  eval_loss = 0.23611209\n",
      "INFO:tensorflow:  global_step = 254\n",
      "INFO:tensorflow:  loss = 0.2312926\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "eval_steps = None\n",
    "\n",
    "train_and_evaluate(train_examples, eval_examples, max_seq_length, estimator, tokenizer, batch_size, eval_steps,\n",
    "                   num_train_steps, output_dir, num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting class probabilities\n",
    "The resulting file with test labels is saved at \"output_dir/predicted_proba_filename\" (path parameters are initialized at \"Parameters\" section). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining documents to predict labels for manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ['This is some string',\n",
    "       'This is another string']\n",
    "test_df = pd.DataFrame(strings, columns =[text_column_name], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading test set from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'results/', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc58c629828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "train_examples = None\n",
    "num_train_steps = None\n",
    "num_warmup_steps = None\n",
    "save_checkpoints_steps = 1000\n",
    "\n",
    "# Creating tokenizer\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file=bert_vocab_path, do_lower_case=True)\n",
    "# Definition of estimator's config\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=output_dir,\n",
    "    save_summary_steps=save_summary_steps,\n",
    "    keep_checkpoint_max=1,\n",
    "    save_checkpoints_steps=save_checkpoints_steps)\n",
    "# Loading config of pretrained Bert model\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_path)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=NUM_LABELS ,\n",
    "    init_checkpoint=bert_init_chkpnt_path,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=False,\n",
    "    use_one_hot_embeddings=False)\n",
    "\n",
    "estimator = get_estimator(model_fn=model_fn, run_config=run_config, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change path if needed\n",
    "test_df = pd.read_csv(os.path.join(corpus_dir, \"test.csv\"), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Predictions!\n",
      "Prediction took time  0:00:00.000168\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 5), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-254\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>EF</th>\n",
       "      <th>INF</th>\n",
       "      <th>ADR</th>\n",
       "      <th>DI</th>\n",
       "      <th>Finding</th>\n",
       "      <th>annotation</th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>p_label_1</th>\n",
       "      <th>p_label_2</th>\n",
       "      <th>p_label_3</th>\n",
       "      <th>p_label_4</th>\n",
       "      <th>p_label_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Стала нервной, капризной, чуть что -сразу визг...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DI[3]|Finding[1]</td>\n",
       "      <td>252298</td>\n",
       "      <td>4</td>\n",
       "      <td>0.450735</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>0.133663</td>\n",
       "      <td>0.987296</td>\n",
       "      <td>0.205825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>После недельного приема дочурка легче стала ос...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EF[2]</td>\n",
       "      <td>252298</td>\n",
       "      <td>7</td>\n",
       "      <td>0.972963</td>\n",
       "      <td>0.023177</td>\n",
       "      <td>0.062206</td>\n",
       "      <td>0.538695</td>\n",
       "      <td>0.067674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Очень радует то, что таблетки не горькие, я ра...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>252298</td>\n",
       "      <td>8</td>\n",
       "      <td>0.074273</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.036345</td>\n",
       "      <td>0.019955</td>\n",
       "      <td>0.065263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>И так с появление ребенка в нашей семье и част...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DI[1]</td>\n",
       "      <td>2457636</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036110</td>\n",
       "      <td>0.023751</td>\n",
       "      <td>0.009731</td>\n",
       "      <td>0.945586</td>\n",
       "      <td>0.035801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Болезнь немного отступала, но потом с новой си...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>INF[3]|DI[2]</td>\n",
       "      <td>2457636</td>\n",
       "      <td>5</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>0.940838</td>\n",
       "      <td>0.051291</td>\n",
       "      <td>0.916195</td>\n",
       "      <td>0.097008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  EF  INF  ADR  DI  \\\n",
       "0  Стала нервной, капризной, чуть что -сразу визг...   0    0    0   1   \n",
       "1  После недельного приема дочурка легче стала ос...   1    0    0   0   \n",
       "2  Очень радует то, что таблетки не горькие, я ра...   0    0    0   0   \n",
       "3  И так с появление ребенка в нашей семье и част...   0    0    0   1   \n",
       "4  Болезнь немного отступала, но потом с новой си...   0    1    0   1   \n",
       "\n",
       "   Finding        annotation  review_id  sentence_id  p_label_1  p_label_2  \\\n",
       "0        1  DI[3]|Finding[1]     252298            4   0.450735   0.098715   \n",
       "1        0             EF[2]     252298            7   0.972963   0.023177   \n",
       "2        0           NEUTRAL     252298            8   0.074273   0.011486   \n",
       "3        0             DI[1]    2457636            2   0.036110   0.023751   \n",
       "4        0      INF[3]|DI[2]    2457636            5   0.095751   0.940838   \n",
       "\n",
       "   p_label_3  p_label_4  p_label_5  \n",
       "0   0.133663   0.987296   0.205825  \n",
       "1   0.062206   0.538695   0.067674  \n",
       "2   0.036345   0.019955   0.065263  \n",
       "3   0.009731   0.945586   0.035801  \n",
       "4   0.051291   0.916195   0.097008  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = predict(test_df, estimator, tokenizer, max_seq_length, num_labels=NUM_LABELS)\n",
    "\n",
    "resulting_df = test_df[text_column_name]\n",
    "resulting_df = pd.concat([test_df, output_df], axis=1)\n",
    "resulting_df.to_csv(os.path.join(output_dir, predicted_proba_filename), index=False)\n",
    "\n",
    "resulting_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.5\n",
    "average='binary'\n",
    "pos_label=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = resulting_df.columns\n",
    "labels = columns[1: 1 + NUM_LABELS]\n",
    "results_numpy = resulting_df.values\n",
    "true_labels = results_numpy[1: 1 + NUM_LABELS]\n",
    "predicted_probabilities = results_numpy[1 + NUM_LABELS: 1 + 2 * NUM_LABELS]\n",
    "predicted_labels = (predicted_probabilities >= threshold).astype(int)\n",
    "for metric_name, metric in METRICS.items():\n",
    "    score = metric(y_true=true_labels, y_pred=predicted_labels, labels=labels, )\n",
    "    print(f\"{metric_name}\\n{score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
